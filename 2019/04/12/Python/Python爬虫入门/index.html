<!DOCTYPE html>
<html>
  <!-- Html Head Tag-->
  <head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="Mute">
  <!-- Open Graph Data -->
  <meta property="og:title" content="Python爬虫入门">
  <meta property="og:description" content="杨柳潇个人主页">
  <meta property="og:site_name" content="杨柳潇的博客">
  <meta property="og:type" content="article">
  <meta property="og:image" content="http://yangliuxiao.top">
  
    <link rel="alternate" href="/atom.xml" title="杨柳潇的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.png">
  

  <!-- Site Title -->
  <title>杨柳潇的博客</title>
  
  <!-- 为了增加TOP按钮，新增的CSS文件 -->
  <link rel="stylesheet" href="/css/TOPButtonStyle.css">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="/css/bootstrap.min.css">
  <!-- Custom CSS -->
  
  <link rel="stylesheet" href="/css/style.light.css">

  <!-- Google Analytics -->
  

</head>

  <body>
    <!-- Page Header -->


<header class="site-header header-background" style="background-image: url(/img/background.jpg)">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="page-title with-background-image">
          <p class="title">Python爬虫入门</p>
          <p class="subtitle"></p>
        </div>
        <div class="site-menu with-background-image">
          <ul>
            
              <li>
                <a href="/">
                  
                  Home
                  
                </a>
              </li>
            
              <li>
                <a href="/archives">
                  
                  Archives
                  
                </a>
              </li>
            
              <li>
                <a href="https://github.com/kevinyang0304">
                  
                  Github
                  
                </a>
              </li>
            
              <li>
                <a href="/About/index.html">
                  
                  About
                  
                </a>
              </li>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
</header>

<article>
  <div class="container typo">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="post-info text-muted">
          
            <!-- Author -->
            <span class="author info">By Mute</span>
          
          <!-- Date -->
          <span class="date-time info">On
            <span class="date">2019-04-12</span>
           <!-- <span class="time">22:13:37</span> -->
          </span>
          
          <!--  Categories  -->
            <span class="categories info">Under 

<a href="/categories/Python技术/">Python技术</a>
</span>
          
        </div>
        <!-- Tags -->
        
          <div class="post-tags text-muted">
            Tags: 

<a class="tag" href="/tags/Python/">#Python</a> <a class="tag" href="/tags/爬虫/">#爬虫</a>


          </div>
        
        <!-- Post Main Content -->
        <div class="post-content">
          <p><a href="#1.网站调查">一、网站调查</a></p>
<blockquote>
<p><a href="#①robots.txt文件">① robots.txt文件</a>                                                                                                                                                                               <a href="#②Sitemap网站地图文件">② Sitemap网站地图文件</a>                                                                                                                                                                  <a href="#③估算网站大小">③ 估算网站大小</a>                                                                                                                                                                                   <a href="#④查看网站所用的技术">④ 查看网站所用的技术（是否动态加载等）</a></p>
</blockquote>
<p><a href="#2.网页下载">二、网页下载</a></p>
<blockquote>
<p><a href="#①下载失败处理">① 下载失败处理</a>                                                                                                                                                                                   <a href="#②失败重试">② 失败重试</a>                                                                                                                                                                                          <a href="#③设置用户代理">③ 设置用户代理</a>                                                                                                                                                                                    <a href="#④链接跟踪">④ 链接跟踪</a>                                                                                                                                                                                           <a href="#⑤下载限速">⑤ 下载限速</a>                                                                                                                                                                                           <a href="#⑥爬虫陷阱">⑥ 爬虫陷阱</a></p>
</blockquote>
<p><a href="#3.数据解析">三、数据解析</a></p>
<blockquote>
<p><a href="#①正则表达式">① 正则表达式</a>                                                                                                                                                                                     <a href="#②BeautifulSoup">② BeautifulSoup</a>                                                                                                                                                                                    <a href="#③lxml">③ lxml</a></p>
<p><a href="#④性能对比">④ 性能对比</a></p>
</blockquote>
<p><a href="#4.爬虫优化">四、爬虫优化</a></p>
<blockquote>
<p><a href="#①缓存支持">① 缓存支持</a>                                                                                                                                                                                       <a href="#②并发下载">② 并发下载</a></p>
</blockquote>
<p><a href="#5.复杂网站爬取">五、复杂网站爬取</a></p>
<blockquote>
<p><a href="#①动态内容">① 动态内容</a>                                                                                                                                                                                             <a href="#②表单交互">② 表单交互</a>                                                                                                                                                                                              <a href="#③验证码">③ 验证码</a></p>
</blockquote>
<p><a href="#6.Scrapy爬虫框架">六、Scrapy爬虫框架</a></p>
<hr>
<h4 id="1-网站调查"><a href="#1-网站调查" class="headerlink" title="1.网站调查"></a>1.网站调查</h4><p>在爬取某个目标网站之前，先对目标网站进行初步的调查，以确定后续的爬虫策略。</p>
<h5 id="①robots-txt文件"><a href="#①robots-txt文件" class="headerlink" title="①robots.txt文件"></a>①robots.txt文件</h5><p><strong>Robots协议（也称为爬虫协议、机器人协议等）</strong>的全称是“网络爬虫排除标准”（Robots Exclusion Protocol），网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取。</p>
<p>文件写法：</p>
<blockquote>
<p>User-agent: <em>     这里的\</em>代表的所有的搜索引擎种类，*是一个通配符</p>
<p>Disallow: /admin/     禁止爬寻admin目录下面的目录</p>
<p>Disallow: /require/     禁止爬寻require目录下面的目录</p>
<p>Disallow: /cgi-bin/*.htm     禁止访问/cgi-bin/目录下的所有以”.htm”为后缀的URL(包含子目录)</p>
<p>Disallow: /<em>?</em>     禁止访问网站中所有包含问号 (?) 的网址</p>
<p>Disallow: /.jpg$     禁止抓取网页所有的.jpg格式的图片</p>
<p>Disallow:/ab/adc.html     禁止爬取ab文件夹下面的adc.html文件。</p>
<p>Allow: /cgi-bin/　    允许爬寻cgi-bin目录下面的目录</p>
<p>Allow: /tmp      允许爬寻tmp的整个目录</p>
<p>Allow: .htm$     仅允许访问以”.htm”为后缀的URL。</p>
<p>Allow: .gif$     允许抓取网页和gif格式图片</p>
<p>Sitemap:     网站地图</p>
</blockquote>
<ul>
<li>一般包含多个文本段，每一个文本段设置一个<strong>用户代理（User-agent）</strong>，然后紧跟着的<strong>Disallow和Allow</strong>字段表示这个用户代理的允许范围。</li>
</ul>
<p>比如<a href="www.baidu.com/robots.txt">百度的robots.txt文件</a></p>
<h5 id="②Sitemap网站地图文件"><a href="#②Sitemap网站地图文件" class="headerlink" title="②Sitemap网站地图文件"></a>②Sitemap网站地图文件</h5><p>网站提供的Sitemap文件可以帮助爬虫定位网站最新的内容，而无须爬取每一个网页。但该文件经常存在缺失、过期或不完整的问题。</p>
<p>比如可以看到<a href="https://www.csdn.net/robots.txt" target="_blank" rel="noopener">CSDN网站的robots.txt</a>中的<a href="https://news.csdn.net/article/sitemap.txt" target="_blank" rel="noopener">sitemap文件</a>是单独放在一个文件中的。</p>
<h5 id="③估算网站大小"><a href="#③估算网站大小" class="headerlink" title="③估算网站大小"></a>③估算网站大小</h5><p>网站的大小会影响我们选取爬取网站的方式，若是小一些的网站，比如只有几百上千的网页URL的网站，则无需考虑并行，直接串行下载就可以了，假如是几百万个网页URL的网站，则必须考虑并行爬虫。</p>
<p>可以使用site: + 目标网站URL的方式在百度或者谷歌等搜索引擎查询结果。因为这些搜索引擎很可能已经爬取过我们感兴趣的网站。</p>
<p><img src="images\图片1.png" alt="images\图片1"></p>
<h5 id="④查看网站所用的技术"><a href="#④查看网站所用的技术" class="headerlink" title="④查看网站所用的技术"></a>④查看网站所用的技术</h5><p>Python有一个可以检查网站构建技术类型的工具模块——<code>buildwith</code>模块</p>
<p><strong>安装方法</strong>直接在终端 pip install buildwith即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> builtwith  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tech_used = builtwith.parse(<span class="string">'http://www.baidu.com'</span>)  </span><br><span class="line">&#123;<span class="string">'javascript-frameworks'</span>: [<span class="string">'jQuery'</span>]&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到百度主页使用了jQuery。</p>
<hr>
<h4 id="2-网页下载"><a href="#2-网页下载" class="headerlink" title="2.网页下载"></a>2.网页下载</h4><p>使用Python的urllib2模块进行网页下载</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> urllib2.urlopen(url).read()</span><br></pre></td></tr></table></figure>
<p>这里要注意网页数据的格式，如果是<code>utf-8</code>的则需要解析成<code>utf-8</code>格式。</p>
<p><code>urllib2.urlopen(url).read().decode(&#39;utf-8&#39;)</code></p>
<p>是<code>GBK</code>格式的也同样。</p>
<h5 id="①下载失败处理"><a href="#①下载失败处理" class="headerlink" title="①下载失败处理"></a>①下载失败处理</h5><p>下载网页时，总会遇到一些无法控制的错误，比如请求的网页不存在等，所以这里需要异常处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    html = urllib2.urlopen(url).read()</span><br><span class="line"><span class="keyword">except</span> urllib2.URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'Download error:'</span>, e.reason</span><br><span class="line">    html = <span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<h5 id="②失败重试"><a href="#②失败重试" class="headerlink" title="②失败重试"></a>②失败重试</h5><p>请求失败时，会给出错误信息<code>urllib2.URLError as e:</code>，可以检查错误信息e中是否有响应状态码字段<code>code</code></p>
<p><code>hasattr(e,&#39;code&#39;)</code></p>
<p>若存在http响应状态码，并且状态码为5xx（即代表服务器错误），则可以尝试多次重复下载，设置最大重复次数。也许在重复下载中，服务器错误已经修复，比如503服务器过载。</p>
<h5 id="③设置用户代理"><a href="#③设置用户代理" class="headerlink" title="③设置用户代理"></a>③设置用户代理</h5><p>默认情况下，urllib2模块下载网页发送请求时，会使用Python-urllib/2.7 作为用户代理。我们可以自己设定用户代理，将其放入封装的request中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;<span class="string">'User-agent'</span>: user_agent&#125;</span><br><span class="line">request = urllib2.Request(url,headers=headers)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    html = urllib2.urlopen(request).read()</span><br><span class="line"><span class="keyword">except</span> urllib2.URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'Download error:'</span>, e.reason</span><br><span class="line">    html = <span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<h5 id="④链接跟踪"><a href="#④链接跟踪" class="headerlink" title="④链接跟踪"></a>④链接跟踪</h5><h6 id="1-通过网站地图跟踪链接"><a href="#1-通过网站地图跟踪链接" class="headerlink" title="1.通过网站地图跟踪链接"></a>1.通过网站地图跟踪链接</h6><p>网站提供的Sitemap文件可以帮助爬虫定位网站最新的内容，而无须爬取每一个网页。但该文件经常存在缺失、过期或不完整的问题。</p>
<h6 id="2-通过ID遍历爬虫"><a href="#2-通过ID遍历爬虫" class="headerlink" title="2.通过ID遍历爬虫"></a>2.通过ID遍历爬虫</h6><p>有时网站会给一些网站设置网站别名，使用连续的ID作为标识，比如<a href="http://xxxx.com/city/1" target="_blank" rel="noopener">http://xxxx.com/city/1</a> 。这样可以对搜索引擎优化起到帮助作用，Web服务器也可以直接只使用ID来匹配数据库里相关的记录。所以我们也可以利用这些连续的ID来遍历整个网站。</p>
<p>但一方面，这样的网站别名并不是每一个网站都有的，另一方面也有一些网站会使用非连续大数作为ID或者直接不使用数值作为ID，这样的情况下，就不能通过ID遍历爬取整个网站了。</p>
<h6 id="3-通过链接跟踪爬取"><a href="#3-通过链接跟踪爬取" class="headerlink" title="3.通过链接跟踪爬取"></a>3.通过链接跟踪爬取</h6><p>让爬虫表现得更像普通用户，通过跟踪所有链接的方式，下载整个网站。</p>
<p><strong>步骤：</strong></p>
<blockquote>
<p>1.通过正则表达式确定需要下载的页面的URL格式</p>
<p>2.将相对链接转换为绝对链接，Python中有urlparse模块可以实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="keyword">import</span> urlparse</span><br><span class="line">&gt; link = urlparse.urljoin(seed_url,re_link) <span class="comment">#seed_url即当前页面URL，re_link是页面上的相对链接</span></span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<p>3.记录已爬取过的链接，避免重复下载。</p>
</blockquote>
<h5 id="⑤下载限速"><a href="#⑤下载限速" class="headerlink" title="⑤下载限速"></a>⑤下载限速</h5><p>如果我们爬取某网站的速度过快，则会面临被封禁或者造成服务器过载的风险。所以需要在两次下载时添加延迟，对爬虫限速。</p>
<h5 id="⑥爬虫陷阱"><a href="#⑥爬虫陷阱" class="headerlink" title="⑥爬虫陷阱"></a>⑥爬虫陷阱</h5><p>一些网站会动态地生成页面内容，这样就会出现无限多的网页，这样页面会无止境链接下去，这种情况被称为<strong>爬虫陷阱</strong>。</p>
<p>想要避免陷入爬虫陷阱，一个简单的方法是记录到达当前网页经过了多少个链接，即深度，达到设置的最大深度就停止爬虫。</p>
<hr>
<h4 id="3-数据解析"><a href="#3-数据解析" class="headerlink" title="3.数据解析"></a>3.数据解析</h4><p>查看目标网站的源代码，了解所要爬取数据的结构，之后就要找办法将数据提取出来。</p>
<h5 id="①正则表达式"><a href="#①正则表达式" class="headerlink" title="①正则表达式"></a>①正则表达式</h5><p>正则表达式就是一些符号组成的公式，由一些符号来定义匹配规则。</p>
<p>正则表达式简单易用，但难以适应网页的变化，健壮性不好，又有构造困难，可读性差等缺点。</p>
<p>关于正则表达式的学习，我的建议是以查询为主，记忆为辅，平常使用的时候直接查询每一个符号代表什么意思，用多了也就自然记住了。</p>
<p>关于正则表达式的规则，可以看<a href="https://morvanzhou.github.io/tutorials/python-basic/basic/13-10-regular-expression/" target="_blank" rel="noopener">这里</a>。</p>
<h5 id="②BeautifulSoup"><a href="#②BeautifulSoup" class="headerlink" title="②BeautifulSoup"></a>②BeautifulSoup</h5><p>Beautiful Soup是一个非常流行的Python模块，该模块可以解析网页，并提供定位内容的便捷接口。</p>
<p>Beautiful Soup会先将下载的HTML内容解析为soup文档。（Beautiful Soup可以正确地解析一些错误的（比如引号缺失、标签未闭合）的HTML。）然后从文档中找到目标元素。</p>
<h5 id="③lxml"><a href="#③lxml" class="headerlink" title="③lxml"></a>③lxml</h5><p>Lxml是基于libxml2这一XML解析库的Python封装。该模块使用C语言编写，解析速度比Beautiful Soup更快，但安装过程较为复杂。</p>
<h5 id="④性能对比"><a href="#④性能对比" class="headerlink" title="④性能对比"></a>④性能对比</h5><div class="table-container">
<table>
<thead>
<tr>
<th>抓取方法</th>
<th>性能</th>
<th>使用难度</th>
<th>安装难度</th>
</tr>
</thead>
<tbody>
<tr>
<td>正则表达式</td>
<td>快</td>
<td>困难</td>
<td>简单（内置）</td>
</tr>
<tr>
<td>Beautiful Soup</td>
<td>慢</td>
<td>简单</td>
<td>简单</td>
</tr>
<tr>
<td>Lxml</td>
<td>快</td>
<td>简单</td>
<td>相对困难</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h4 id="4-爬虫优化"><a href="#4-爬虫优化" class="headerlink" title="4.爬虫优化"></a>4.爬虫优化</h4><h5 id="①缓存支持"><a href="#①缓存支持" class="headerlink" title="①缓存支持"></a>①缓存支持</h5><p>1.磁盘缓存</p>
<p>实现简单，但受本地文件系统的限制（比如文件名不能相同、每个卷或者目录下的文件数目有限）</p>
<p>2.数据库缓存</p>
<p>加载速度慢，但NoSQL可以避免文件系统的种种限制，并且在并发环境下更加高效。</p>
<h5 id="②并发下载"><a href="#②并发下载" class="headerlink" title="②并发下载"></a>②并发下载</h5><p>……待续</p>

        </div>
      </div>
    </div>
	
	  <span id="back-to-top">
	  <a href="#top"><img src="/img/top3.png"></a>
	</span>
	
  </div>

</article>



    <!-- Footer -->
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
	  <!-- 
        <p class="copyright text-muted">
          Theme By <a target="_blank" href="https://github.com/levblanc">Levblanc.</a>
          Inspired By <a target="_blank" href="https://github.com/klugjo/hexo-theme-clean-blog">Clean Blog.</a>
        <p class="copyright text-muted">
          Powered By <a target="_blank" href="https://hexo.io/">Hexo.</a>
        </p>
		-->
      </div>
    </div>
  </div>
</footer>


    <!-- After Footer Scripts -->
<script src="/js/highlight.pack.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function(event) {
    var codeBlocks = Array.prototype.slice.call(document.getElementsByTagName('pre'))
    codeBlocks.forEach(function(block, index) {
      hljs.highlightBlock(block);
    });
  });
</script>

  </body>
</html>

